{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>total_workers</th>\n",
       "      <th>resource_mining</th>\n",
       "      <th>total_army_value</th>\n",
       "      <th>total_army</th>\n",
       "      <th>time</th>\n",
       "      <th>fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>25310</td>\n",
       "      <td>2625</td>\n",
       "      <td>11</td>\n",
       "      <td>808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>28154</td>\n",
       "      <td>5825</td>\n",
       "      <td>65</td>\n",
       "      <td>836</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>7361</td>\n",
       "      <td>1400</td>\n",
       "      <td>16</td>\n",
       "      <td>390</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>8488</td>\n",
       "      <td>2125</td>\n",
       "      <td>50</td>\n",
       "      <td>390</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>4589</td>\n",
       "      <td>550</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  total_workers  resource_mining  total_army_value  total_army  \\\n",
       "0           0             66            25310              2625          11   \n",
       "1           1             46            28154              5825          65   \n",
       "2           2             45             7361              1400          16   \n",
       "3           3             34             8488              2125          50   \n",
       "4           4             27             4589               550           3   \n",
       "\n",
       "   time  fraction  \n",
       "0   808         1  \n",
       "1   836         2  \n",
       "2   390         3  \n",
       "3   390         3  \n",
       "4   261         1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "\n",
    "df = pd.read_csv('csv_dateien/starcraftFinalcsvs/stackedRun.csv')\n",
    "\n",
    "conditions = [\n",
    "    (df['fraction'] == \"Protoss\"), #1\n",
    "    (df['fraction'] == \"Terraner\"), #2\n",
    "    (df['fraction'] == \"Zerg\"), #3\n",
    "]\n",
    "\n",
    "values = [1, 2, 3]\n",
    "\n",
    "df[\"fraction\"] = np.select(conditions, values)\n",
    "\n",
    "\n",
    "dfPrepSample = df.drop(columns=[\"player\",\"winner\",\"replay_filename\"])\n",
    "dfPrepSample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,    66, 25310, ...,    11,   808,     1],\n",
       "       [    1,    46, 28154, ...,    65,   836,     2],\n",
       "       [    2,    45,  7361, ...,    16,   390,     3],\n",
       "       ...,\n",
       "       [  844,    25,  4774, ...,     4,   251,     0],\n",
       "       [  845,    45, 13131, ...,     3,   429,     0],\n",
       "       [  846,    35,  9132, ...,    66,   458,     0]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfFeatures = dfPrepSample.copy()\n",
    "dfLabels = dfPrepSample.pop(\"total_army_value\")\n",
    "dfFeatures = np.array(dfFeatures)\n",
    "dfFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = layers.Normalization()\n",
    "normalize.adapt(dfFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_model = tf.keras.Sequential([normalize, layers.Dense(64), layers.Dense(1)])\n",
    "\n",
    "sc_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "104/104 [==============================] - 0s 643us/step - loss: 17234800.0000\n",
      "Epoch 2/160\n",
      "104/104 [==============================] - 0s 568us/step - loss: 17163774.0000\n",
      "Epoch 3/160\n",
      "104/104 [==============================] - 0s 559us/step - loss: 17018672.0000\n",
      "Epoch 4/160\n",
      "104/104 [==============================] - 0s 515us/step - loss: 16793516.0000\n",
      "Epoch 5/160\n",
      "104/104 [==============================] - 0s 593us/step - loss: 16488087.0000\n",
      "Epoch 6/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 16114994.0000\n",
      "Epoch 7/160\n",
      "104/104 [==============================] - 0s 564us/step - loss: 15679791.0000\n",
      "Epoch 8/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 15195593.0000\n",
      "Epoch 9/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 14667104.0000\n",
      "Epoch 10/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 14104713.0000\n",
      "Epoch 11/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 13522834.0000\n",
      "Epoch 12/160\n",
      "104/104 [==============================] - 0s 567us/step - loss: 12925813.0000\n",
      "Epoch 13/160\n",
      "104/104 [==============================] - 0s 573us/step - loss: 12327698.0000\n",
      "Epoch 14/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 11733435.0000\n",
      "Epoch 15/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 11148336.0000\n",
      "Epoch 16/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 10580678.0000\n",
      "Epoch 17/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 10034185.0000\n",
      "Epoch 18/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 9513734.0000\n",
      "Epoch 19/160\n",
      "104/104 [==============================] - 0s 568us/step - loss: 9022594.0000\n",
      "Epoch 20/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 8559230.0000\n",
      "Epoch 21/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 8126056.0000\n",
      "Epoch 22/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 7726205.5000\n",
      "Epoch 23/160\n",
      "104/104 [==============================] - 0s 573us/step - loss: 7354623.0000\n",
      "Epoch 24/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 7012742.0000\n",
      "Epoch 25/160\n",
      "104/104 [==============================] - 0s 559us/step - loss: 6697360.5000\n",
      "Epoch 26/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 6408361.0000\n",
      "Epoch 27/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 6138579.0000\n",
      "Epoch 28/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 5889570.0000\n",
      "Epoch 29/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 5654902.0000\n",
      "Epoch 30/160\n",
      "104/104 [==============================] - 0s 568us/step - loss: 5433663.0000\n",
      "Epoch 31/160\n",
      "104/104 [==============================] - 0s 573us/step - loss: 5222662.0000\n",
      "Epoch 32/160\n",
      "104/104 [==============================] - 0s 565us/step - loss: 5018591.5000\n",
      "Epoch 33/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 4821776.5000\n",
      "Epoch 34/160\n",
      "104/104 [==============================] - 0s 564us/step - loss: 4629784.0000\n",
      "Epoch 35/160\n",
      "104/104 [==============================] - 0s 556us/step - loss: 4441468.5000\n",
      "Epoch 36/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 4255413.0000\n",
      "Epoch 37/160\n",
      "104/104 [==============================] - 0s 574us/step - loss: 4071586.2500\n",
      "Epoch 38/160\n",
      "104/104 [==============================] - 0s 592us/step - loss: 3890255.7500\n",
      "Epoch 39/160\n",
      "104/104 [==============================] - 0s 574us/step - loss: 3710715.5000\n",
      "Epoch 40/160\n",
      "104/104 [==============================] - 0s 559us/step - loss: 3532558.2500\n",
      "Epoch 41/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 3357200.0000\n",
      "Epoch 42/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 3183318.5000\n",
      "Epoch 43/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 3012251.7500\n",
      "Epoch 44/160\n",
      "104/104 [==============================] - 0s 555us/step - loss: 2843454.7500\n",
      "Epoch 45/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 2677737.2500\n",
      "Epoch 46/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 2515390.0000\n",
      "Epoch 47/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 2356919.7500\n",
      "Epoch 48/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 2202110.5000\n",
      "Epoch 49/160\n",
      "104/104 [==============================] - 0s 574us/step - loss: 2051321.3750\n",
      "Epoch 50/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 1905703.3750\n",
      "Epoch 51/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 1764984.6250\n",
      "Epoch 52/160\n",
      "104/104 [==============================] - 0s 568us/step - loss: 1629637.3750\n",
      "Epoch 53/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 1500159.7500\n",
      "Epoch 54/160\n",
      "104/104 [==============================] - 0s 539us/step - loss: 1376674.1250\n",
      "Epoch 55/160\n",
      "104/104 [==============================] - 0s 604us/step - loss: 1260253.0000\n",
      "Epoch 56/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 1149879.1250\n",
      "Epoch 57/160\n",
      "104/104 [==============================] - 0s 546us/step - loss: 1046861.9375\n",
      "Epoch 58/160\n",
      "104/104 [==============================] - 0s 573us/step - loss: 950247.3750\n",
      "Epoch 59/160\n",
      "104/104 [==============================] - 0s 575us/step - loss: 860987.8750\n",
      "Epoch 60/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 778656.2500\n",
      "Epoch 61/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 703034.7500\n",
      "Epoch 62/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 634525.5625\n",
      "Epoch 63/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 572186.3125\n",
      "Epoch 64/160\n",
      "104/104 [==============================] - 0s 545us/step - loss: 516525.5000\n",
      "Epoch 65/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 466622.1562\n",
      "Epoch 66/160\n",
      "104/104 [==============================] - 0s 564us/step - loss: 422628.4375\n",
      "Epoch 67/160\n",
      "104/104 [==============================] - 0s 564us/step - loss: 384030.6562\n",
      "Epoch 68/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 349865.1875\n",
      "Epoch 69/160\n",
      "104/104 [==============================] - 0s 559us/step - loss: 320427.1562\n",
      "Epoch 70/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 295008.9688\n",
      "Epoch 71/160\n",
      "104/104 [==============================] - 0s 579us/step - loss: 272948.2500\n",
      "Epoch 72/160\n",
      "104/104 [==============================] - 0s 548us/step - loss: 254117.5625\n",
      "Epoch 73/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 238054.6562\n",
      "Epoch 74/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 224243.0312\n",
      "Epoch 75/160\n",
      "104/104 [==============================] - 0s 583us/step - loss: 212147.9219\n",
      "Epoch 76/160\n",
      "104/104 [==============================] - 0s 568us/step - loss: 201687.5000\n",
      "Epoch 77/160\n",
      "104/104 [==============================] - 0s 568us/step - loss: 192694.4844\n",
      "Epoch 78/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 184360.2188\n",
      "Epoch 79/160\n",
      "104/104 [==============================] - 0s 566us/step - loss: 177031.5156\n",
      "Epoch 80/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 170339.9375\n",
      "Epoch 81/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 164096.4062\n",
      "Epoch 82/160\n",
      "104/104 [==============================] - 0s 557us/step - loss: 158082.1875\n",
      "Epoch 83/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 152531.4844\n",
      "Epoch 84/160\n",
      "104/104 [==============================] - 0s 569us/step - loss: 147260.1562\n",
      "Epoch 85/160\n",
      "104/104 [==============================] - 0s 556us/step - loss: 142084.1094\n",
      "Epoch 86/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 137154.9844\n",
      "Epoch 87/160\n",
      "104/104 [==============================] - 0s 585us/step - loss: 132194.5000\n",
      "Epoch 88/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 127387.0703\n",
      "Epoch 89/160\n",
      "104/104 [==============================] - 0s 566us/step - loss: 122648.3906\n",
      "Epoch 90/160\n",
      "104/104 [==============================] - 0s 714us/step - loss: 118073.9453\n",
      "Epoch 91/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 113573.6172\n",
      "Epoch 92/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 109110.9688\n",
      "Epoch 93/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 104890.0938\n",
      "Epoch 94/160\n",
      "104/104 [==============================] - 0s 545us/step - loss: 100569.9531\n",
      "Epoch 95/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 96344.7812\n",
      "Epoch 96/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 92299.9453\n",
      "Epoch 97/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 88146.3047\n",
      "Epoch 98/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 84215.3438\n",
      "Epoch 99/160\n",
      "104/104 [==============================] - 0s 568us/step - loss: 80527.3828\n",
      "Epoch 100/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 76580.9297\n",
      "Epoch 101/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 72945.8906\n",
      "Epoch 102/160\n",
      "104/104 [==============================] - 0s 559us/step - loss: 69356.6172\n",
      "Epoch 103/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 65875.1406\n",
      "Epoch 104/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 62461.0664\n",
      "Epoch 105/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 59086.2930\n",
      "Epoch 106/160\n",
      "104/104 [==============================] - 0s 548us/step - loss: 55882.2109\n",
      "Epoch 107/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 52753.7773\n",
      "Epoch 108/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 49779.8672\n",
      "Epoch 109/160\n",
      "104/104 [==============================] - 0s 555us/step - loss: 46777.8516\n",
      "Epoch 110/160\n",
      "104/104 [==============================] - 0s 583us/step - loss: 43923.1289\n",
      "Epoch 111/160\n",
      "104/104 [==============================] - 0s 596us/step - loss: 41297.7148\n",
      "Epoch 112/160\n",
      "104/104 [==============================] - 0s 588us/step - loss: 38581.8164\n",
      "Epoch 113/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 36049.2539\n",
      "Epoch 114/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 33574.7227\n",
      "Epoch 115/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 31179.4570\n",
      "Epoch 116/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 28917.7930\n",
      "Epoch 117/160\n",
      "104/104 [==============================] - 0s 594us/step - loss: 26796.0918\n",
      "Epoch 118/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 24677.9609\n",
      "Epoch 119/160\n",
      "104/104 [==============================] - 0s 554us/step - loss: 22642.9102\n",
      "Epoch 120/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 20777.8613\n",
      "Epoch 121/160\n",
      "104/104 [==============================] - 0s 545us/step - loss: 18997.4102\n",
      "Epoch 122/160\n",
      "104/104 [==============================] - 0s 545us/step - loss: 17281.9863\n",
      "Epoch 123/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 15686.5049\n",
      "Epoch 124/160\n",
      "104/104 [==============================] - 0s 548us/step - loss: 14187.7021\n",
      "Epoch 125/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 12766.5400\n",
      "Epoch 126/160\n",
      "104/104 [==============================] - 0s 568us/step - loss: 11452.9160\n",
      "Epoch 127/160\n",
      "104/104 [==============================] - 0s 554us/step - loss: 10224.8799\n",
      "Epoch 128/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 9078.6484\n",
      "Epoch 129/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 8024.2559\n",
      "Epoch 130/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 7046.9653\n",
      "Epoch 131/160\n",
      "104/104 [==============================] - 0s 558us/step - loss: 6165.4912\n",
      "Epoch 132/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 5357.9790\n",
      "Epoch 133/160\n",
      "104/104 [==============================] - 0s 573us/step - loss: 4620.1597\n",
      "Epoch 134/160\n",
      "104/104 [==============================] - 0s 575us/step - loss: 3967.3533\n",
      "Epoch 135/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 3379.6533\n",
      "Epoch 136/160\n",
      "104/104 [==============================] - 0s 545us/step - loss: 2846.5808\n",
      "Epoch 137/160\n",
      "104/104 [==============================] - 0s 557us/step - loss: 2392.1443\n",
      "Epoch 138/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 1982.9077\n",
      "Epoch 139/160\n",
      "104/104 [==============================] - 0s 568us/step - loss: 1634.9838\n",
      "Epoch 140/160\n",
      "104/104 [==============================] - 0s 573us/step - loss: 1329.6987\n",
      "Epoch 141/160\n",
      "104/104 [==============================] - 0s 565us/step - loss: 1072.8739\n",
      "Epoch 142/160\n",
      "104/104 [==============================] - 0s 567us/step - loss: 856.7842\n",
      "Epoch 143/160\n",
      "104/104 [==============================] - 0s 563us/step - loss: 675.5283\n",
      "Epoch 144/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 523.9567\n",
      "Epoch 145/160\n",
      "104/104 [==============================] - 0s 670us/step - loss: 403.2245\n",
      "Epoch 146/160\n",
      "104/104 [==============================] - 0s 713us/step - loss: 305.5074\n",
      "Epoch 147/160\n",
      "104/104 [==============================] - 0s 561us/step - loss: 228.8640\n",
      "Epoch 148/160\n",
      "104/104 [==============================] - 0s 573us/step - loss: 167.4680\n",
      "Epoch 149/160\n",
      "104/104 [==============================] - 0s 555us/step - loss: 120.5004\n",
      "Epoch 150/160\n",
      "104/104 [==============================] - 0s 559us/step - loss: 85.5239\n",
      "Epoch 151/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 59.2910\n",
      "Epoch 152/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 40.7863\n",
      "Epoch 153/160\n",
      "104/104 [==============================] - 0s 544us/step - loss: 27.2075\n",
      "Epoch 154/160\n",
      "104/104 [==============================] - 0s 566us/step - loss: 17.9085\n",
      "Epoch 155/160\n",
      "104/104 [==============================] - 0s 569us/step - loss: 11.3757\n",
      "Epoch 156/160\n",
      "104/104 [==============================] - 0s 650us/step - loss: 7.1221\n",
      "Epoch 157/160\n",
      "104/104 [==============================] - 0s 653us/step - loss: 4.3399\n",
      "Epoch 158/160\n",
      "104/104 [==============================] - 0s 597us/step - loss: 2.5874\n",
      "Epoch 159/160\n",
      "104/104 [==============================] - 0s 553us/step - loss: 1.4756\n",
      "Epoch 160/160\n",
      "104/104 [==============================] - 0s 549us/step - loss: 0.8248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f79b306170>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_model.fit(dfFeatures, dfLabels, epochs=160)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
